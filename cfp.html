<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="First Shared Task on Automatic Minuting">

  <title>First Shared Task on Automatic Minuting</title>

  <!-- Bootstrap core CSS -->
  <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- Fira Sans font -->
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans&display=swap" rel="stylesheet">

  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <!-- Custom styles for this template -->
  <link href="styles.css" rel="stylesheet">

  <!-- icons -->
  <link rel="stylesheet" href="./font-awesome-4.1.0/css/font-awesome.min.css">

</head>

<body>

  <!-- NAVBAR ================================================== -->

  <div class="navbar-wrapper">
    <div class="container">
      <div class="navbar navbar-inverse navbar-static-top" role="navigation">
        <div class="container">

          <!-- MENU BUTTON FOR SMALL SCREENS + LOGO ================================ -->

          <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="header-logo-link" href="index.html">
              <div class="header-logo">
                <span class="letter-highlight">Auto</span>matic
                <span class="letter-highlight">Min</span>uting
                 <!--<span class="letter-highlight">S</span>hared Task-->
                @ <span class="letter-highlight">Interspeech 2021</span>
              </div>
            </a>
          </div>

          <!-- MENU OPTIONS ================================================== -->

          <div class="navbar-collapse collapse pull-right">
            <ul class="nav navbar-nav">
              <li class="active"><a href="index.html">Home</a></li>
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Call for Participation <b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="cfp.html">CfP</a></li>
                   <!--<li><a href="cfp.html#topics">Topics of Interest</a></li>-->
                  <!--<li><li><a href="cfp.html#sharedtasks">Shared Tasks</a></li>-->
                  <li><a href="submission.html">Submission Information</a></li>
                  <li><a href="index.html#important-dates">Important Dates</a></li>
                  <!--<li><a href="cfp.html#journal">Journal Extension</a></li>-->
                  <!--<li><a href="cfp.html#keynotes">Keynote Speakers</a></li>-->
                  <!--<li><a href="cfp.html#committees">Committees</a></li>-->
                </ul>
              </li>
              <!--<li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Shared Tasks <b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="sharedtasks.html">Call for Participation</a></li>
                  <li><a href="sharedtasks.html#clscisumm">CL-SciSumm</a></li>
                  <li><a href="sharedtasks.html#laysumm">CL-LaySumm</a></li>
                  <li><a href="sharedtasks.html#longsumm">LongSumm</a></li>
                  <li><a href="sharedtasks.html#register">Registration</a></li>
                  <li><a href="sharedtasks.html#dates">Important Dates</a></li>
                  <li><a href="sharedtasks.html#organizers">Organizers</a></li>
                </ul>
              </li>-->
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Program<b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="keynotespeakers.html">Keynote Speakers</a></li>
                  <li><a href="program.html">Program Outline</a></li>
                  <li><a href="accepted-papers.html">Accepted Submissions</a></li>
                </ul>
              </li>
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Committees<b class="caret"></b></a>
                <ul class="dropdown-menu">
                  <li><a href="organizingcommittee.html">Organizing Committee</a></li>
                  <!--<li><a href="steeringcommittee.html">Steering Committee</a></li>-->
                  <li><a href="scientificcommittee.html">Scientific Committee</a></li>
                  <!--<li><a href="contact.html">Contact Us</a></li>-->
                </ul>
              </li>
              <!--<li><a href="previousworkshops.html">Other Workshops</a></li>-->
               <!--<li><a href="https://www.interspeech2021.org/">Venue</a></li>-->
            </ul>
          </div>

          <!-- MENU OPTIONS END ================================ -->

        </div>
      </div>
    </div>
  </div>

  <!-- MAIN CONTENT ============================================= -->

  <div class="container marketing navbar-spacing">

    <div class="row">
      <div class="col-md-12">

        <!-- CFP INTRODUCTION ================================================== -->

        <!-- <h1>The 6<sup>th</sup> Computational Linguistics Scientific Document Summarization Shared
          Task (CL-SciSumm 2020)</h1> -->

        <h1>AutoMin 2021 Call for Participation</h1>

        <p>
          <a href="https://forms.office.com/Pages/ResponsePage.aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAANAAfe8TVJUM1NLRzdIOTE4REtETDJCVjFDOU1OTFo1Ni4u"><button type="button" class="btn btn-primary">AutoMin Registration</button></a>
        </p>

       <!-- <hr class="featurette-divider"> -->

       <!-- <h2>Navigation</h2>

        <ul>
          <li>
            <a href="#clscisumm">AutoMin 2020</a>
          </li>
          <li>
            <a href="#laysumm">CL-LaySumm 2020</a>
          </li>
          <li>
            <a href="#longsumm">LongSumm 2020</a>
          </li>
          <li>
            <a href="#register">Registration</a>
          </li>
          <li>
            <a href="#dates">Important Dates</a>
          </li>
          <li>
            <a href="#organizers">Organizing Committee</a>
          </li>
        </ul> -->

        <hr class="featurette-divider">

        <!-- CL-SciSumm ======================================================== -->

        <h2 id="automin">AutoMin 2021: The 1<sup>st</sup> Shared Task on Automatic Minuting</h2>

        <p>
         When most of our interactions went virtual, the need for automatic support for smooth running of the online events such as project meetings became more intense. Summarizing meeting contents is one of them. Meeting minutes keep a record of what was discussed at a meeting. It is usually a written document with little or no structure (perhaps a hierarchical bulleted list) aimed at informing the participants and non-participants of what happened during the meeting. ‘Automatic minuting’ tools would be a useful addition to better comprehend the meeting contents quickly. People adopt different styles when ‘taking notes’ or ‘recording minutes’ of the meeting. The minutes also depend on the category of the meeting, the intended audience, and the goal or objective of the meeting. Text or speech summarization methods known from the past would rank close to this task. However, Automatic Minuting is challenging due to the absence of agreed-upon guidelines, variety of minuting practices, and lack of extensive background research. 
        </p>
        <p>
         We propose AutoMin, the first shared task on automatic minuting of meeting proceedings. Our objective is to drive community efforts towards understanding the challenges of the task and develop tools for this important use case especially in the current world which had to go on-line far more than expected. With this shared task, we would invite the speech and natural language processing community to investigate the challenges of automatic minuting with real meeting data in two different settings: technical project meetings (both in English and Czech) and parliamentary proceedings (English). 
        </p>

        <h3>AutoMin Task</h3>

        <p>
          We propose one main task and two subsidiary tasks. The subsidiary tasks are optional.
        </p>

        <ul>
            <strong>Main Task A:</strong> The main task consists of automatically creating minutes from multiparty meeting transcripts. The generated minute would be evaluated both via automatic and manual metrics.
          <li>
            <strong>Task B:</strong> Given a pair of meeting transcript and minute, the task is to identify whether the minute belongs to the transcript. During our data preparation from meetings on similar topics, we found that this task could be challenging given the similarity in various named-entities.
          </li>
          <li>
            <strong>Task C:</strong> Given a pair of minutes, the task is to identify whether the two minutes belong to the same or different meetings. This sub-task is important as we want to uncover how minutes created by two different persons for the same meeting may differ in content and coverage.
          </li>
        </ul>
        
        <h3>Procedure Overview</h3>
        <ol>
          <li>
            We will first release ‘trial’ data, to illustrate the task and the formats used.
          </li>
          <li>
            Later, we will release available training and dev-set data which will match in a format exactly with the main test data.
          </li>
          <li>
            The training and dev-set data will contain the inputs and the reference outputs. (E.g. for Task A, this will be the transcripts and one or sometimes more manually created minutes.)
          </li>
          <li>
            The shared task itself will run for a week in late May: you will be given test inputs and no reference outputs. You will be expected to submit your outputs during the evaluation week, before the System Output Submission deadline.
          </li>
           <li>
            You will be expected to write a paper describing your system and submit it before the System Report Submission deadline.
          </li>
           <li>
            Due to time constraints, we expect that the official results of the task will be available only after the System Report Submission deadline; you will have a chance to include them in your report before the Camera-Ready deadline for the report.
          </li>
           <li>
            Based on the results and system reports, we will invite about 50% of teams to write an extended description of their system, to form a special issue of PBML.
          </li>
        </ol>
        
        
        
        <h3>Data</h3>
        
        <p>
          The data for the shared task would be available in the following Github repository. More task-specific details to use the data would be provided in due time on our website.
          <a href="https://github.com/ELITR/automin-2021">https://github.com/ELITR/automin-2021</a>
        </p>
        
        <p>
         Aside from the data we release, we recommend the following datasets to use in your training although our domains do not match: 
        </p>
        <ul>
        <li>
          <b>CNN-Daily Mail</b>: You can use the scripts in <a href="https://github.com/abisee/cnn-dailymail">here</a> to generate the non-anonymized version of the corpus.
        </li>
         <li>
           The <a href="http://groups.inf.ed.ac.uk/ami/corpus/overview.shtml">AMI Meeting Corpus</a>. You can download the summary corpus from <a href="https://github.com/gcunhase/AMICorpusXML">here</a>.
        </li>
         <li>
           The <a href="http://groups.inf.ed.ac.uk/ami/icsi/download/">ICSI Meeting Corpus</a>
        </li>
         <li>
           The <a href="https://podcastsdataset.byspotify.com">Spotify Podcast Dataset</a>. 
        </li>
        </ul>
          Task participants are allowed to use any further data. When submitting, you need to indicate which data was used to train your system:
          <ul>
            <li>
              Minimal - minimal submissions use only the in-domain training data
            </li>
            <li>
              Constraint - constraint submissions use the in-domain training data and CNN-DM, AMI, and ICSI.
            </li>
            <li>
              Non-constraint - non-constraint submissions may use any other data.
            </li>
          </ul>
         <p>
         In any case, please clearly describe which data was used in what way in your system paper. A comprehensive list of summarization datasets could be found here: 
        <ul>
          <li>
            <a href="https://gist.github.com/napsternxg/2750479273e0621c5aa697bf89843428 ">https://gist.github.com/napsternxg/2750479273e0621c5aa697bf89843428 </a>
          </li>
          <li>
            <a href="https://github.com/xcfcode/Summarization-Papers">https://github.com/xcfcode/Summarization-Papers </a>
          </li>
        </ul>
         </p>
        <h3>Evaluation</h3>

       <h5>Manual Evaluation of Task A </h5>
          For the manual evaluation of Task A, we will use several quality criteria which are common for evaluation of text samples produced by automatic language generation systems: adequacy, relevance, coverage, readability, and grammaticality. Unlike other similar tasks, textual coherence will not be taken into account, because we believe meeting minutes are not always supposed to have a coherent textual form. The manual evaluation will be carried out blindly by our annotators. If you would like to contribute to the evaluation, it would be highly appreciated. Please get in touch.
       <h5>Automatic Evaluation of Task A</h5>
          ROUGE would be the primary metric for automatic evaluation. However, given the abstractive nature of some minutes, we would also use two recent semantic-level metrics: BERTScore and Sentence Mover Score.
      <h5>Evaluation of Tasks B and C</h5>
        For the subsidiary tasks (B and C), accuracy would be the evaluation metric.
        
        <h3>Submission Platform</h3>

        <p>
          We would ask our participants to host their system-runs in their own GitHub repository and share the link with us with exactly the system requirements/environment to run their code. Also, they would submit their automatically generated outputs. In general, you will be expected to submit the outputs of your system in Task A and optionally in Task B and/or Task C, in some fairly simple format based on plain text.

        </p>
        
        <h3>Publication</h3>
        
        <p>
          All teams are required to submit a brief technical report describing their method. Please use the Interspeech <a href="https://www.interspeech2021.org/author-resources">template</a> for your system description reports. All reports must be a minimum of 2 pages and a maximum of 5 pages excluding references. Reports must be written in English. Each report would be reviewed by atleast two reviewers. Authors would submit their papers using EasyChair (link will be updated soon). The proceedings would be added to the <a href="https://www.isca-speech.org/iscaweb/index.php/online-archive">ISCA archive</a>.
        </p>
        
        <p>
          We would additionally invite selected authors to submit a full-paper to a special issue of the <a href="https://ufal.mff.cuni.cz/pbml">Prague Bulletin of Mathematical Linguistics (PBML)</a> which is indexed in Google Scholar, DOAJ, etc. The papers may undergo further review as decided by the organizing committee.
        </p>

        <h3>Contact</h3>

        <p>
          For further information about this task and dataset, please contact:
        </p>

        <ul>
          <li>
            Tirthankar Ghosal <a href="mailto:ghosal@ufal.mff.cuni.cz ">ghosal@ufal.mff.cuni.cz</a>
          </li>
          <li>
            Anja Nedoluzhko <a href="mailto:nedoluzko@ufal.mff.cuni.cz">nedoluzko@ufal.mff.cuni.cz</a>
          </li>
        </ul>

    <!-- FOOTER ========================================== -->
  
    <hr><br />
  
    <footer>
     <div class="footer-wrapper">
        <div class="footer-left">
          <p>Contact: <a href="mailto:minute@ufal.mff.cuni.cz">minute@ufal.mff.cuni.cz</a></p>
          <p>Follow us: <a href="https://twitter.com/elitrorg">https://twitter.com/elitrorg</a></p>
          <p>&copy; 2020 European Live Translator, A Horizon 2020 Project, <a href="https://elitr.eu/">https://elitr.eu/</a></p>
         <!-- <p>
            <a href="https://www.pexels.com/photo/library-university-books-students-12064/">
              Photo of Library Room by Tamas Meszaros (Free to use)
            </a>
          </p>
          <p>
            <a href="https://pxhere.com/en/photo/1575603">
              Picture of a network by asawin form PxHere (Creative Commons CC0)
            </a>
          </p>-->
        </div>
        <div class="footer-right">
          <a href="#">Back to top</a>
        </div>
     </div>
    </footer>

  </div>

  <!-- Bootstrap core JavaScript ================================================== -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
  <script src="./dist/js/bootstrap.min.js"></script>
  <script src="./assets/js/docs.min.js"></script>

</body>

</html>
