<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="SummDial">
  <link rel="icon" type="image/gif/png" href="images/elitr.png">
  <title>SummDial @ SIGDial 2021</title>

  <!-- Bootstrap core CSS -->
  <link href="./dist/css/bootstrap.min.css" rel="stylesheet">

  <!-- Fira Sans font -->
  <link href="https://fonts.googleapis.com/css?family=Fira+Sans&display=swap" rel="stylesheet">

  <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  <!-- Custom styles for this template -->
  <link href="styles.css" rel="stylesheet">

  <!-- icons -->
  <link rel="stylesheet" href="./font-awesome-4.1.0/css/font-awesome.min.css">
  
  <style>
            div {
                 text-align: justify;
                 text-justify: inter-word;
                }
    </style>

</head>

<body>

  <!-- NAVBAR ================================================== -->

  <div class="navbar-wrapper">
    <div class="container">
      <div class="navbar navbar-inverse navbar-static-top" role="navigation">
        <div class="container">

          <!-- MENU BUTTON FOR SMALL SCREENS + LOGO ================================ -->

          <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="header-logo-link" href="">
              <div class="header-logo">
                <span class="letter-highlight">SummDial</span>
             
               
                @ <span class="letter-highlight">SIGDial 2021</span>
                <span class="letter-highlight">July 29, 2021</span>
              </div>
             
            </a>
            
          </div>

          <!-- MENU OPTIONS ================================================== -->

          <div class="navbar-collapse collapse pull-right">
            <ul class="nav navbar-nav">
              <li class=""><a href="https://elitr.eu/"><img src="images/elitr.png" alt="logo" height="100"/></a></li>
              
              <li class=""><a href="https://www.sigdial.org"><img src="images/sigdial.png" alt="logo" height="100"/></a></li>
              <li class=""><a href="https://ufal.mff.cuni.cz"><img src="images/charles2.png" alt="logo" height="100"/></a></li>
              <li class=""><a href="">Home</a></li>
              <li class="dropdown">
                <a href="#" class="dropdown-toggle" data-toggle="dropdown">SummDial<b class="caret"></b></a>
                <ul class="dropdown-menu">
              <!--    <li><a href="">CfP</a></li>
                  <li><a href="">Submission Information</a></li>
                  <li><a href="">Important Dates</a></li>
                  <li><a href="">Keynote Speaker</a></li>
                  <li><a href="">Panel</a></li>
                  <li><a href="">Accepted Submissions</a></li>
                  <li><a href="">Program Outline</a></li>
                  <li><a href="">Program Committee</a></li>
                  <li><a href="">Organizing Committee</a></li>
                  <li><a href="">Contact</a></li> -->
                  <li><a href="https://www.sigdial.org/files/workshops/conference22/">SIGDial 2021</a></li>
                  <li><a href="#program-schedule">SummDial Schedule</a></li>
                 <li><a href="summdial-cfp.html">Call for Papers</a></li>
                </ul>
              </li>
              <li><a href="https://elitr.github.io/automatic-minuting/index.html">AutoMin</a></li>
              
            </ul>
          </div>

          <!-- MENU OPTIONS END ================================ -->

        </div>
      </div>
    </div>
  </div>
    <!-- MAIN CONTENT ============================================= -->

  <div class="container marketing navbar-spacing">

    <div class="row">
      <div class="col-md-12">
   
        <h2 id="sdial"><b>SummDial</b></h2> <h3><b>SummDial: A <a href="http://www.colips.org/conferences/sigdial2021/wp/">SIGDial 2021</a> Special Session on Summarization of Dialogues and Multi-Party Meetings</b></h3>
  
        <p>
          With a sizeable working population of the world going virtual, resulting in information overload from multiple online meetings, imagine how convenient it would be to just hover over past calendar invites and get concise summaries of the meeting proceedings? How about automatically minuting a multimodal multi-party meeting? Are minutes and multi-party dialogue summaries the same? We believe Automatic Minuting is challenging. There are possibly no agreed-upon guidelines to take minutes, and people adopt different styles to record minutes of the meeting. The minutes also depend on the meeting's category, the intended audience, and the goal or objective of the meeting. 
        </p>
        <p>
          The SummDial special session at <a href="https://www.sigdial.org/files/workshops/conference22/">SIGDial 2021</a> intends to instigate discussions on these challenges. Our goal for this SIGDial special session would be to stimulate intense discussions around this topic and set the tone for further interest, research, and collaboration in both Speech and Natural Language Processing communities. We are also launching a shared task on <a href="https://elitr.github.io/automatic-minuting/">Automatic Minuting (AutoMin)</a> at <a href="https://www.interspeech2021.org">Interspeech 2021</a>. 
        </p>
        <h2> Updates </h2>
        <p>
        <b><mark>1. <a href="https://www.sigir.org/wp-content/uploads/2022/02/p12.pdf">SummDial @ SIGDial 2021</mark></a>Report on the SIGDial 2021 Special Session on Summarization of Dialogues and Multi-Party Meetings (SummDial)</a></mark></b> published in SIGIR Forum.
        </p>
         <p>
          <b><mark>2. Recording of <a href="https://drive.google.com/file/d/1HRdIZvwctfrgGKKkQ1ZqwcC7WcBuoq_l/view">SummDial @ SIGDial 2021</mark></a> special session.</b>.
        </p>
        <p>
          <b>3. The SIGDial 2021 Proceedings are now live! <a href="https://sigdial.org/sites/default/files/workshops/conference22/Proceedings/index.html">SIGDial 2021 Proceedings</a></b>.
        </p>
        <p>
          <b>4. You can follow our updates on Twitter <a href="https://twitter.com/hashtag/SummDial2021?src=hashtag_click">&#35;SummDial2021</a> <a href="https://twitter.com/ElitrOrg">@ElitrOrg</a> </a></b>.
        </p>
        <p>
          <b>5. We are organizing a breakout session at <a href="http://www.colips.org/conferences/sigdial2021/wp/">SIGDial</a> on <b>July 29, 2021 at 20:00 Singapore Time</b>. Please join us to discuss the challenges of meeting and dialogue summarization and our activities in the EU H2020 Project <a href="https://elitr.eu">ELITR</a>. Join link available at the <a href="http://www.colips.org/conferences/sigdial2021/wp/technical-session/">SIGDial Technical Program Schedule</a></b>.
        </p>
        <!--<p>
          <b><mark>5. <a href="http://www.colips.org/conferences/sigdial2021/wp/registration/">Registration to SummDial</a> is live now until July 28, 2021 (30 SGD only).</mark></b>
        </p>-->
       <!-- <p>
          <b><mark>6. SummDial @ SIGDial 2021 will be an all-virtual event on July 29, 2021 at 22:30 Singapore Time. Join link available at the <a href="http://www.colips.org/conferences/sigdial2021/wp/technical-session/">SIGDial Technical Program Schedule</a></mark></b>.
        </p> -->
        <hr class="featurette-divider">

        
         <h1>Keynote Speaker</h1>

   

    <div class="row featurette">
      <div class="col-md-9 bio-text">
        <h2><a href="https://scholar.google.com/citations?user=eVYrz4EAAAAJ&hl=en">Klaus Zechner</a></h2>
        <a name="keynote"></a>
        <p class="lead">Educational Testing Service, United States</p>
        <p>Klaus Zechner received his Ph.D. from Carnegie Mellon University in 2001 for research on automated speech summarization. This work was published at SIGIR-2001 and in Computational Linguistics (2002).
Klaus Zechner is now a Senior Research Scientist in the Natural Language Processing Lab in the Research and Development Division of Educational Testing Service (ETS) in Princeton, New Jersey, USA. Since joining ETS in 2002, he has been pioneering research and development of technologies for automated scoring of non-native speech, leading large R&D projects dedicated to the continuous improvement of automated speech scoring technology. He holds more than 20 patents on technology related to SpeechRater®, an automated speech scoring system he and his team have been developing at ETS. SpeechRater is currently used operationally as sole score for the TOEFL® Practice Online (TPO) Speaking assessment and, in a hybrid scoring approach, also for TOEFL iBT Speaking.
Klaus Zechner authored more than 80 peer-reviewed publications in journals, book chapters, conference and workshop proceedings, and research reports. He also edited a book on automated speaking assessment that was published by Routledge in 2019; it provides an overview of the current state-of-the-art in automated speech scoring of spontaneous non-native speech. </p>
        <!-- <p>youngsr "at" ornl.gov</p> -->
        <p> <h2>Title of the Talk - Who Discussed What With Whom: Is Meeting Summarization A Solved Problem?</h2>
        <h3><b>Abstract :</b></h3>
       <i>While creating audio and video records of multi-party meetings has become easier than ever in recent years, obtaining access to the key contents or a summary of a meeting is non-trivial. 
        In this talk, I will first provide an overview of the main differences between multi-party meetings and news articles – the prototypical domain for most research on summarization so far. 
        In the second part of the talk, a few example approaches to meeting summarization will be presented and discussed, spanning from early research to late-breaking system papers. 
        Finally, I will conclude with thoughts about the current state-of-the-art of the field of meeting summarization and open issues that still need to be addressed by the research community.</i>
        </p>
      </div>
      <div class="col-md-3 bio-photo">
        <img class="featurette-image img-responsive imagedropshadow" src="images/klaus-zechner.jpg" alt="Klaus Zechner">
      </div>
    </div>
        
          <hr class="featurette-divider">
      <h1>Panel Discussion </h1>  
      <h2> Dialogue and Meeting Summarization: Taking Stock and Looking Ahead, Moving Towards Automatic Minuting </h2>
      <a name="panel"></a>
    <div class="row featurette">
      <div class="col-md-9 bio-text">
        <h2 class="featurette-name-heading"><a href="https://www.cis.upenn.edu/~nenkova/">Ani Nenkova</a></h2>
        <p class="lead">Adobe Research, United States</p>
        <p>Ani Nenkova is a Principal Scientist at Adobe Research, leading the Document Intelligence Lab at Adobe-Maryland. Her main areas of research are computational linguistics and artificial intelligence, with emphasis on developing computational methods for the analysis of text quality and style, discourse, affect recognition, and summarization. She obtained her Ph.D. degree in computer science from Columbia University. Ani is a co-editor-in-chief of the Transactions of the Association for Computational Linguistics (TACL). She was a member of the editorial board of Computational Linguistics (2009--2011) and an associate editor for the IEEE/ACM Transactions on Audio, Speech, and Language Processing (2015--2018). She regularly serves as an area chair/senior program committee member for ACL, NAACL, and AAAI.</p>
        <!-- <p>pattonrm "at" ornl.gov</p> -->
      </div>
      <div class="col-md-3 bio-photo">
        <img class="featurette-image img-responsive imagedropshadow" src="images/ani_nenkova.jpeg" alt="Ani Nenkova">
      </div>
    </div>
        
        
    <div class="row featurette">
      <div class="col-md-9 bio-text">
        <h2 class="featurette-name-heading"><a href="https://www.cc.gatech.edu/~dyang888/">Diyi Yang</a></h2>
        <p class="lead">Georgia Institute of Technology, United States</p>
        <p>Diyi Yang is an assistant professor in the School of Interactive Computing at Georgia Tech. Her research focuses on Computational Social Science, and Natural Language Processing. Diyi received her PhD from Language Technologies Institute at Carnegie Mellon University. Her work has been published at leading NLP/HCI conferences, and also resulted in multiple paper award (nominations) from EMNLP 2015, ICWSM 2016, SIGCHI 2019, CSCW 2020, SIGCHI 2021. She is named as one of Forbes 30 Under 30 in Science in 2021, and a recipient of IEEE AI 10 to Watch in 2020. </p>
        <!-- <p>pattonrm "at" ornl.gov</p> -->
      </div>
      <div class="col-md-3 bio-photo">
        <img class="featurette-image img-responsive imagedropshadow" src="images/Diyi_Yang.jpg" alt="Diyi Yang">
      </div>
    </div>
  
    <div class="row featurette">
      <div class="col-md-9 bio-text">
        <h2 class="featurette-name-heading"><a href="https://www.microsoft.com/en-us/research/people/chezhu/">Chenguang Zhu</a></h2>
        <p class="lead">Microsoft Cognitive Services Research Group, United States</p>
        <p>Dr. Chenguang Zhu is a Principal Research Manager in Microsoft Cognitive Services Research Group. His research in NLP covers text summarization, knowledge graph, and task-oriented dialogue. Dr. Zhu has led teams to achieve first places in multiple NLP competitions, including CommonsenseQA, CommonGen, FEVER, CoQA, ARC and SQuAD v1.0. He holds a Ph.D. degree in Computer Science from Stanford University.</p>
        <!-- <p>pattonrm "at" ornl.gov</p> -->
      </div>
      <div class="col-md-3 bio-photo">
        <img class="featurette-image img-responsive imagedropshadow" src="images/chenguang_zhu.jpeg" alt="Chenguang Zhu">
      </div>
    </div>
         <hr class="featurette-divider">
        
       <!-- <h1>Accepted Papers</h1>
        
       <ul>
          <li> <h4>Coreference-Aware Dialogue Summarization, Authors: Zhengyuan Liu, Ke Shi and Nancy Chen (Long) </h4></li>
          <li> <h4>Weakly Supervised Extractive Summarization with Attention, Authors:  Yingying Zhuang, Yichao Lu and Simi Wang (Long) </h4></li>
          <li> <h4>Incremental temporal summarization in multi-party meetings, Authors: Ramesh Manuvinakurike, Saurav Sahay, Wenda Chen and Lama Nachman (Long)  </h4></li>
          <li> <h4>Mitigating Topic Bias when Detecting Decisions in Dialogue, Authors:  Mladen Karan, Prashant Khare, Patrick Healey and Matthew Purver (Short) </h4></li>
        </ul>
        
        <hr class="featurette-divider"> -->

       
        <h1>Program Schedule</h1>
        <a name="program-schedule"></a>
       <table class="table program">
            <thead>
              <tr>
                <th scope="col"><mark>Join link available under Special Session SS1</mark> at <a href="http://www.colips.org/conferences/sigdial2021/wp/technical-session/">SIGDial 2021 Technical Program Schedule</a></th>
                <th scope="col">SGT</th>
                <th scope="col">CEST</th>
                <th scope="col">EDT</th>
                <th scope="col">IST</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <th scope="row">Opening</th>
                <td class="tz">22:30-22:45</td>
                <td class="tz">16:30-16:45</td>
                <td class="tz">10:30-10:45</td>
                <td class="tz">20:00-20:15</td>
              </tr>
              <tr>
                <th scope="row">Keynote 1: <a href="#keynote">Klaus Zechner &mdash; Who discussed what with whom: is meeting summarization a solved problem?</a></th>
                <td class="tz">22:45-23:30</td>
                <td class="tz">16:45-17:30</td>
                <td class="tz">10:45-11:30</td>
                <td class="tz">20:15-21:00</td>
              </tr>
              <tr>
                <th scope="row">Break - 5 minutes</th>
                <td class="tz">23:30-23:35</td>
                <td class="tz">17:30-17:35</td>
                <td class="tz">11:30-11:35</td>
                <td class="tz">21:00-21:05</td>
              </tr>
              <tr>
                <th scope="row">Long Paper 1: <a href="https://arxiv.org/pdf/2106.08556.pdf">Coreference-Aware Dialogue Summarization - Zhengyuan Liu, Ke Shi, and Nancy Chen</a></th>
                <td class="tz">23:35-23:55</td>
                <td class="tz">17:35-17:55</td>
                <td class="tz">11:35-11:55</td>
                <td class="tz">21:05-21:25</td>
              </tr>
              <tr>
                <th scope="row">Long Paper 2: <a href="https://assets.amazon.science/a1/98/dfa7608e420c935a1a667f4c6bb5/weakly-supervised-extractive-summarization-with-attention.pdf">Weakly Supervised Extractive Summarization with Attention - Yingying Zhuang, Yichao Lu, and Simi Wang </a></th>
                <td class="tz">23:55-00:15<sup>+1</sup></td>
                <td class="tz">17:55-18:15</td>
                <td class="tz">11:55-12:15</td>
                <td class="tz">21:25-21:45</td>
              </tr>
               <tr>
                <th scope="row">Long Paper 3: <a href="https://drive.google.com/file/d/1k3XhT1CIobvx4epDj_D2m5yA-irNbeo3/view?usp=sharing">Incremental temporal summarization in multi-party meetings - Ramesh Manuvinakurike, Saurav Sahay, Wenda Chen, and Lama Nachman </a></th>
                <td class="tz">00:15<sup>+1</sup>-00:35<sup>+1</sup></td>
                <td class="tz">18:15-18:35</td>
                <td class="tz">12:15-12:35</td>
                <td class="tz">21:45-22:05</td>
              </tr>
               <tr>
                <th scope="row">Break - 10 minutes</th>
                <td class="tz">00:35<sup>+1</sup>-00:45<sup>+1</sup></td>
                <td class="tz">18:35-18:45</td>
                <td class="tz">12:35-12:45</td>
                <td class="tz">22:05-22:15</td>
              </tr>
               <tr>
                <th scope="row">Panel Discussion: <a href="#panel">Dialogue and Meeting Summarization: Taking Stock and Looking Ahead, Towards Automatic Minuting - Ani Nenkova, Diyi Yang, Klaus Zechner, and Chenguang Zhu </a></th>
                <td class="tz">00:45<sup>+1</sup>-01:45<sup>+1</sup></td>
                <td class="tz">18:45-19:45</td>
                <td class="tz">12:45-13:45</td>
                <td class="tz">22:15-23:15</td>
              </tr>
              <tr>
                <th scope="row">Break - 5 minutes</th>
                <td class="tz">01:45<sup>+1</sup>-01:50<sup>+1</sup></td>
                <td class="tz">19:45-19:50</td>
                <td class="tz">13:45-13:50</td>
                <td class="tz">23:15-23:20</td>
              </tr>
               <tr>
                <th scope="row">Short Paper 1: <a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/karan-et-al21sigdial.pdf">Mitigating Topic Bias when Detecting Decisions in Dialogue - Mladen Karan, Prashant Khare, Patrick Healey, and Matthew Purver  </a></th>
                <td class="tz">01:50<sup>+1</sup>-02:10<sup>+1</sup></td>
                <td class="tz">19:50-20:10</td>
                <td class="tz">13:50-14:10</td>
                <td class="tz">23:20-23:40</td>
              </tr>
              <tr>
                <th scope="row">Short Paper 2: <a href="https://youtu.be/0KG4SB0ykjs">Creating a data set of abstractive summaries of turn-labeled spoken human-computer conversations - Iris Hendrickx and Virginia Meijer</a></th>
                <td class="tz">02:10<sup>+1</sup>-02:30<sup>+1</sup></td>
                <td class="tz">20:10-20:30</td>
                <td class="tz">14:10-14:30</td>
                <td class="tz">23:40-00:00<sup>+1</sup></td>
              </tr>
              <tr>
                <th scope="row">Short Paper 3: <a href="https://drive.google.com/file/d/1a5SKMZT_TrGkTahbqdUuwXKxjv4tPEN0/view?usp=sharing">Dynamic Sliding Window for Meeting Summarization - Zhengyuan Liu and Nancy Chen</a></th>
                <td class="tz">02:30<sup>+1</sup>-02:50<sup>+1</sup></td>
                <td class="tz">20:30-20:50</td>
                <td class="tz">14:30-14:50</td>
                <td class="tz">00:00<sup>+1</sup>-00:20<sup>+1</sup></td>
              </tr>
                <tr>
                <th scope="row">Closing</th>
                <td class="tz">02:50<sup>+1</sup>-03:00<sup>+1</sup></td>
                <td class="tz">20:50-21:00</td>
                <td class="tz">14:50-15:00</td>
                <td class="tz">00:20<sup>+1</sup>-00:30<sup>+1</sup></td>
              </tr>
            </tbody>
          </table>
        
        <hr class="featurette-divider">
      
         <h3 id="mdpi-journal"><b>Extended Versions to Journal</b></h3>
        <p>
          We would invite selected authors to submit a full-paper to a special issue of the open access <a href="https://www.mdpi.com/journal/information">Information journal from MDPI</a> which is indexed within Scopus, ESCI (Web of Science), Ei Compendex, DBLP, and many other databases. The journal submissions would undergo further review. Authors of invited papers should be aware that the final submitted manuscript must provide a minimum of 50% new content and not exceed 30% copy/paste from the proceedings paper.
        </p>
   <h3 id="pc"><b>Program Committee</b></h3>
        <ul>
          <li><a href="https://www.idiap.ch/~sparida/">Shantipriya Parida</a>, Idiap Research Institute, Switzerland</li>
          <li><a href="https://sovankumarsahoo.wixsite.com/sovankumarsahoo">Sovan Kumar Sahoo</a>, Indian Institute of Technology Patna, India</li>
          <li><a href="https://www.linkedin.com/in/sandeep-kumar-a51329197/">Sandeep Kumar</a>, Indian Institute of Technology Patna, India</li>
          <li><a href="https://elitr.eu/tirthankar-ghosal/">Tirthankar Ghosal</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
          <li><a href="https://ufal.mff.cuni.cz/muskaan-singh-0">Muskaan Singh</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
          <li><a href="https://ufal.mff.cuni.cz/anna-nedoluzhko">Anja Nedoluzhko</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
          <li><a href="https://ufal.mff.cuni.cz/ondrej-bojar">Ondřej Bojar</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
        </ul>
   <h3 id="organizers"><b>Organizers</b></h3>
        <ul>
          <li><a href="https://elitr.eu/tirthankar-ghosal/">Tirthankar Ghosal</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
          <li><a href="https://ufal.mff.cuni.cz/muskaan-singh-0">Muskaan Singh</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
          <li><a href="https://ufal.mff.cuni.cz/anna-nedoluzhko">Anja Nedoluzhko</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
          <li><a href="https://ufal.mff.cuni.cz/ondrej-bojar">Ondřej Bojar</a>, Institute of Formal and Applied Linguistics, Charles University, Czech Republic </li>
        </ul>
   <h3 id="contact"><b>Contact</b></h3> <h4> <a href="mailto:ghosal@ufal.mff.cuni.cz">ghosal@ufal.mff.cuni.cz</a></h4>
      <!--</div>
       
        <div class="frame"> -->
        <h3><b>Media Partner</b></h3>
          <a href="https://www.mdpi.com/journal/information"> <img src="images/Information logo.png" alt="Information Journal MDPI" height="200"/></a>
        </div>
   <!-- FOOTER ========================================== -->
  
    <hr><br />
  
    <footer>
     <div class="footer-wrapper">
        <div class="footer-left">
          <p>Follow us: <a href="https://twitter.com/elitrorg">https://twitter.com/elitrorg</a></p>
          <p>&copy; 2020 European Live Translator, A Horizon 2020 Project, <a href="https://elitr.eu/">https://elitr.eu/</a></p>
          <p>Ondřej Bojar would also like to acknowledge the support from the grant <a href="https://ufal.mff.cuni.cz/grants/neurem3">19-26934X (NEUREM3)</a> of the Czech Science Foundation.</p>
          <p>Website Template Acknowledgement: <a href="https://sdproc.org/2021/">SDP 2021</a></p>
         <!-- <p>
            <a href="https://www.pexels.com/photo/library-university-books-students-12064/">
              Photo of Library Room by Tamas Meszaros (Free to use)
            </a>
          </p>
          <p>
            <a href="https://pxhere.com/en/photo/1575603">
              Picture of a network by asawin form PxHere (Creative Commons CC0)
            </a>
          </p>-->
        </div>
        <div class="footer-right">
          <a href="#">Back to top</a>
        </div>
     </div>
    </footer>

  </div>
  
  <!-- Bootstrap core JavaScript ================================================== -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
  <script src="./dist/js/bootstrap.min.js"></script>
  <script src="./assets/js/docs.min.js"></script>

</body>

</html>
